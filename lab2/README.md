# Отчет по Лабораторной работе №2 (обычная)

## Задача
 - Написать “плохой” Dockerfile, в котором есть не менее трех “bad practices” по написанию докерфайлов

 - Написать “хороший” Dockerfile, в котором эти плохие практики исправлены

 - В Readme описать каждую из плохих практик в плохом докерфайле, почему она плохая и как в хорошем она была исправлена, как исправление повлияло на результат

 - В Readme описать 2 плохих практики по работе с контейнерами. ! Не по написанию докерфайлов, а о том, как даже используя хороший докерфайл можно накосячить именно в работе с контейнерами.

## Плохой Dockerfile

```bash
FROM python:latest

RUN apt-get update
RUN pip install requests
RUN apt-get install -y nginx

COPY app/ /app

CMD ["python", "/app/main.py"]

```
#### FROM python: latest
Данная практика плоха т.к. при каких-то изменениях в Python наш проект может сломаться

#### RUN apt-get update
#### RUN pip install html
#### RUN pip install nginx
В данной практике мы используем несколько отдельных RUN
Каждый RUN создаёт отдельный слой образ становится больше и дольше собирается
Так же нет очистки кеша, что забивает память
Установка ненужных пакетов Приложение не использует Nginx, но пакет занимает место и увеличивает образ.
#### СOPY app/ /app
копируютя все файлы

#### CMD ["python", "/app/main.py"]
В данной практике мы указываем полный путь к файлу и для передачи аргументов придется переписать CMD

Так же нет WORKDIR, то есть не фиксируется рабочая область

Нет очистки кеша После apt-get update не очищается кеш (/var/lib/apt/lists/*) — увеличивает размер образа.

## Хороший Dockerfile

```bash
FROM python:3.11

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY app/ ./

RUN apt-get update && \
    apt-get install -y --no-install-recommends build-essential gcc && \
    rm -rf /var/lib/apt/lists/*


ENTRYPOINT ["python"]
CMD ["app.py"]
```
#### FROM python:3.11
хорошо, потому что версия зафиксирована и всегда одно и то же ставится.

#### WORKDIR /app
хорошо, потому-что зафиксировали рабочую область

#### COPY requirements.txt ./

#### RUN apt-get update && \
####     apt-get install -y --no-install-recommends build-essential gcc && \
####     rm -rf /var/lib/apt/lists/*

Очистка apt-кеша

#### RUN pip install --no-cache-dir -r requirements.txt
хорошо, потому что пакеты и питон-библиотеки ставятся чисто, без мусора и с кешированием.

#### ENTRYPOINT ["python"]
#### CMD ["app.py"]
хорошо, потому что удобно запускать и легко менять аргументы без переписывания образа.

### Как исправления повлияют на результат

#### Размер образа уменьшится за счет очистки кеша и удаления пакетов после RUN

#### Время сборки стало меньше или неизменного файла requirements.txt

## Плохие практики по работе с контейнерами

### Первая bad-практиа это не ограничивать контейнер памятью и % ЦП

```bash
docker run -d --name lab my-lab:latest
```
Практика выше плоха тем, что контейнер мы не ограчили в ресурсах памяти и процессора
Ниже хорошая практика

```bash
docker run -d --name lab \
  --memory=128m --cpus="0.3" \
  my-lab:latest
```

### Вторая bad-практика это давать слишком много прав контейнеру

```bash
docker run --privileged -d --name lab lapp:latest
```
Практика выше плоха тем, что контейнер получил слишком много прав и при уязвимостях может обернутся плохим
Ниже хорошая практика

```bash
docker run -d --name lab \
  --cap-drop ALL --cap-add NET_BIND_SERVICE \
  lapp:latest
```
Выше показан хороший пример контейнера без чрезмерных прав, теперь он может слушать порты без управления хоста

## Выводы
Во время выполнения лабораторной работы я узнал как ограничивать потребление ЦП контейнером т.к. при чрезмерном потреблении ПК мог лагать
Так же теперь буду лучше составлять Dockerfile'ы, конечно без :latest чтобы в случайное время не сломать приложение.
